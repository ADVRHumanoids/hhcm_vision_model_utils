{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“¦ COCO to YOLO Segmentation Converter\n",
    "\n",
    "## Overview\n",
    "This notebook provides a comprehensive pipeline for extracting custom subsets from the COCO dataset and converting them to YOLO segmentation format. It handles downloading images, converting annotations (both bounding boxes and segmentation polygons), and creating a properly structured YOLO dataset ready for training.\n",
    "\n",
    "## Features\n",
    "- **Custom Subset Extraction**: Select specific classes and sample sizes from COCO\n",
    "- **Multi-Split Support**: Handles both train and validation splits with balancing\n",
    "- **YOLO Format Conversion**: Converts COCO annotations to YOLO segmentation format\n",
    "- **Parallel Processing**: Multi-threaded image downloading for faster processing\n",
    "- **Automatic Dataset Structure**: Creates proper YOLO directory structure with data.yaml\n",
    "- **Visualization Tools**: Built-in visualization for verifying conversions\n",
    "- **Duplicate Handling**: Ensures no overlap between train and validation sets\n",
    "\n",
    "\n",
    "## Configuration\n",
    "Edit the `my_categories` dictionary to select desired classes and the sampling parameters:\n",
    "```python\n",
    "my_categories = {\n",
    "    \"person\": 0,\n",
    "    \"car\": 1,\n",
    "    \"dog\": 2,\n",
    "    # Add your classes here\n",
    "}\n",
    "N_sample_train = 400  # Minimum samples per class for training\n",
    "N_sample_valid = 100  # Minimum samples per class for validation\n",
    "```\n",
    "\n",
    "## Requirements\n",
    "- COCO annotation files (instances_train2017.json, instances_val2017.json)\n",
    "- Python packages: `pycocotools`, `matplotlib`, `requests`, `pyyaml`, `progress`\n",
    "- Sufficient disk space for images\n",
    "\n",
    "## Usage Instructions\n",
    "1. **Configure Categories**: Edit `my_categories` dict with desired classes\n",
    "2. **Set Sample Sizes**: Adjust `N_sample_train` and `N_sample_valid`\n",
    "3. **Run Extraction**: Execute cells to download and convert dataset\n",
    "4. **Verify**: Use visualization cells to check conversions\n",
    "5. **Download**: Zip file is created automatically (Google Colab)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install progress\n",
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from progress.bar import Bar\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "\n",
    "#cocoTrain=COCO('/content/instances_train2017.json')\n",
    "#cocoVal=COCO('/content/instances_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4yAIfQ80pPo"
   },
   "outputs": [],
   "source": [
    "def COCONames_to_COCOId(coco, COCO_name):\n",
    "    return coco.getCatIds(catNms=[COCO_name])[0];\n",
    "\n",
    "def COCOId_to_COCONames(coco, COCO_id):\n",
    "  cats = coco.loadCats(coco.getCatIds())\n",
    "  for c in cats:\n",
    "    if c['id'] == COCO_id:\n",
    "      return c['name']\n",
    "  return -1\n",
    "\n",
    "# Function to convert COCO format to YOLO\n",
    "def convert_coco_to_yolo(coco, img_ids, output_labels_dir):\n",
    "    for img_id in img_ids:\n",
    "        img_info = coco.loadImgs([img_id])[0]\n",
    "        ann_ids = coco.getAnnIds(imgIds=[img_id])\n",
    "        annotations = coco.loadAnns(ann_ids)\n",
    "\n",
    "        # Prepare YOLO format label\n",
    "        label_file_path = Path(output_labels_dir + img_info['file_name'])\n",
    "        label_file = label_file_path.with_suffix(\".txt\")\n",
    "        with open(label_file, 'w+') as f:\n",
    "            for ann in annotations:\n",
    "                category_id = ann['category_id']\n",
    "                if not category_id in catIds:\n",
    "                  continue\n",
    "                bbox = ann['bbox']\n",
    "                segmentation = ann['segmentation']\n",
    "\n",
    "                x = bbox[0]\n",
    "                y = bbox[1]\n",
    "                w = bbox[2]\n",
    "                h = bbox[3]\n",
    "\n",
    "                # Finding midpoints\n",
    "                x_centre = (x + (x+w))/2\n",
    "                y_centre = (y + (y+h))/2\n",
    "\n",
    "                # Normalization\n",
    "                x_centre = x_centre / img_info['width']\n",
    "                y_centre = y_centre / img_info['height']\n",
    "                w = w / img_info['width']\n",
    "                h = h / img_info['height']\n",
    "\n",
    "                # Limiting upto fix number of decimal places\n",
    "                x_centre = format(x_centre, '.6f')\n",
    "                y_centre = format(y_centre, '.6f')\n",
    "                w = format(w, '.6f')\n",
    "                h = format(h, '.6f')\n",
    "\n",
    "                # Since YOLO train wants cat from 0 to N, we have to remap\n",
    "                new_category_id = my_categories[COCOId_to_COCONames(cocoTrain, category_id)]\n",
    "\n",
    "                f.write(f\"{new_category_id} {x_centre} {y_centre} {w} {h} \")\n",
    "                #If segmentation exists, append the polygons (optional)\n",
    "                if isinstance(segmentation, list):  # Polygons\n",
    "\n",
    "                  segmentation_points_list = []\n",
    "                  for segmentation in ann['segmentation']:\n",
    "\n",
    "                    # segmentation_points = [str(\\\n",
    "                    #   float(point) / (img_info['width']-1) if i % 2 == 0 \\\n",
    "                    #   else float(point) / (img_info['height']-1)) \\\n",
    "                    #   for i, point in enumerate(segmentation)]\n",
    "\n",
    "                    #cap to 1.0 so yolo does not complain\n",
    "                    segmentation_points = [\n",
    "                        str(min(float(point) / (img_info['width'] - 1), 1.0)) if i % 2 == 0\n",
    "                        else str(min(float(point) / (img_info['height'] - 1), 1.0))\n",
    "                        for i, point in enumerate(segmentation)\n",
    "                    ]\n",
    "                    \n",
    "                    segmentation_points_list.append(' '.join(segmentation_points))\n",
    "                    segmentation_points_string = ' '.join(segmentation_points_list)\n",
    "                    line = '{} '.format(segmentation_points_string)\n",
    "                    f.write(line)\n",
    "                    segmentation_points_list.clear()\n",
    "                  f.write(f\"\\n\")\n",
    "                else:\n",
    "                  f.write(f\"\\n\")\n",
    "\n",
    "\n",
    "def get_ids(coco, cat_names, N):\n",
    "  catIds = coco.getCatIds(cat_names);\n",
    "  imgIds = []\n",
    "  for cat in catIds:\n",
    "    imgIdsAll = coco.getImgIds(catIds=cat)\n",
    "    to_select = N\n",
    "    if len(imgIdsAll) < N:\n",
    "      to_select = len(imgIdsAll)\n",
    "      print(f\"WARNING: cat {cat} has only {len(imgIdsAll)}, when {N} requested\")\n",
    "\n",
    "    imgIdsSelection = np.random.choice(imgIdsAll, size=to_select, replace=False)\n",
    "\n",
    "    imgIds += imgIdsSelection.tolist()\n",
    "\n",
    "  #remove duplicates\n",
    "  imgIds_no_dup = list(dict.fromkeys(imgIds))\n",
    "\n",
    "  return imgIds_no_dup\n",
    "\n",
    "\n",
    "def download_copy_images(imgs_folder, output_img_dir, coco, img_ids):\n",
    "  imgs_info = coco.loadImgs(img_ids)\n",
    "  for img_info in imgs_info:\n",
    "    #check if file is already in img folder\n",
    "    if not os.path.isfile(imgs_folder + img_info['file_name']):\n",
    "      # Save the image into a local folder\n",
    "      img_data = requests.get(img_info['coco_url']).content\n",
    "      with open(imgs_folder + img_info['file_name'], 'wb') as handler:\n",
    "          handler.write(img_data)\n",
    "\n",
    "    shutil.copyfile(imgs_folder + img_info['file_name'], output_img_dir + img_info['file_name'])\n",
    "\n",
    "def imageName_to_cocoId(coco, imageName):\n",
    "  imgs_info = coco.loadImgs(coco.getImgIds())\n",
    "  for img_info in imgs_info:\n",
    "    if img_info['file_name'] == imageName:\n",
    "      return img_info['id']\n",
    "  return -1\n",
    "\n",
    "def job(img_info, imgs_folder, output_img_dir):\n",
    "  #check if file is already in img folder\n",
    "  if not os.path.isfile(imgs_folder + img_info['file_name']):\n",
    "    # Save the image into a local folder\n",
    "    img_data = requests.get(img_info['coco_url']).content\n",
    "    with open(imgs_folder + img_info['file_name'], 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "  shutil.copyfile(imgs_folder + img_info['file_name'], output_img_dir + img_info['file_name'])\n",
    "\n",
    "def download_copy_images_pool(imgs_folder, output_img_dir, coco, img_ids, pool_count=5):\n",
    "  pool = Pool(pool_count)\n",
    "  partial_support = partial(job, imgs_folder = imgs_folder, output_img_dir = output_img_dir)\n",
    "  imgs_info = coco.loadImgs(img_ids)\n",
    "  bar = Bar('Downloading and copying...', max=len(imgs_info))\n",
    "  for i in pool.imap(partial_support, imgs_info):\n",
    "    bar.next()\n",
    "  bar.finish()\n",
    "  pool.close()\n",
    "  pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igFyiExsRlpN"
   },
   "outputs": [],
   "source": [
    "imageName_to_cocoId(cocoTrain, \"000000033931.jpg\")\n",
    "\n",
    "test_ids = get_ids(cocoTrain, [\"car\"], 60)\n",
    "\n",
    "download_copy_images_pool(img_folder, \"/content/test/\", cocoTrain, test_ids)\n",
    "\n",
    "img_folder = \"/content/imgs/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKBGAK4omRvy"
   },
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ejHl6Tcdu_4"
   },
   "outputs": [],
   "source": [
    "my_categories = {\n",
    "    \"person\": 0,\n",
    "    \"sports ball\": 1,\n",
    "    \"bottle\": 2,\n",
    "    \"wine glass\": 3,\n",
    "    \"cup\": 4,\n",
    "    \"fork\": 5,\n",
    "    \"knife\": 6,\n",
    "    \"spoon\": 7,\n",
    "    \"bowl\": 8,\n",
    "    \"banana\": 9,\n",
    "    \"apple\": 10,\n",
    "    \"sandwich\": 11,\n",
    "    \"orange\": 12,\n",
    "    \"carrot\": 13,\n",
    "    \"book\": 14,\n",
    "    \"clock\": 15,\n",
    "    \"vase\": 16,\n",
    "    \"scissors\": 17,\n",
    "    \"toothbrush\": 18,\n",
    "}\n",
    "\n",
    "#laser is 309/76 (80/20)\n",
    "\n",
    "#for each category, it is assured that AT LEAST this number of occurencies exist\n",
    "# (because on same image multiple categories can be present, and also multiple occurencies\n",
    "# of same category)\n",
    "N_sample_train = 400\n",
    "N_sample_valid = 100\n",
    "\n",
    "output_name = \"./coco_subset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lm01JcRaCkh0",
    "outputId": "651df9ce-d60d-4e05-d428-5905f8e8cd5b"
   },
   "outputs": [],
   "source": [
    "# get all images containing given categories, select at random\n",
    "\n",
    "id_train = get_ids(cocoTrain, list(my_categories.keys()), N_sample_train)\n",
    "id_valid = get_ids(cocoVal, list(my_categories.keys()), N_sample_valid)\n",
    "\n",
    "#add to valid set from the non selected among the train\n",
    "id_valid_from_train = []\n",
    "catIds = cocoTrain.getCatIds(list(my_categories.keys()));\n",
    "for cat in catIds:\n",
    "    imgIdsCat = cocoVal.getImgIds(catIds=cat)\n",
    "    if len(imgIdsCat) < N_sample_valid:\n",
    "      print(len(imgIdsCat))\n",
    "      ids = cocoTrain.getImgIds(catIds=cat)\n",
    "      i = 0\n",
    "      for id in ids:\n",
    "        if id not in id_train:\n",
    "          id_valid_from_train.append(id)\n",
    "          i = i+1\n",
    "          if (i + len(imgIdsCat)) >= N_sample_valid:\n",
    "            print(f\"cat {cat} had only {len(imgIdsCat)}, added {i}\")\n",
    "            break\n",
    "\n",
    "id_valid_from_train = list(dict.fromkeys(id_valid_from_train))\n",
    "\n",
    "#remove from train things that are in valid, this should never happen, but who knows\n",
    "print(len(id_train))\n",
    "id_train = [i for i in id_train if i not in id_valid]\n",
    "id_train = [i for i in id_train if i not in id_valid_from_train]\n",
    "print(len(id_train))\n",
    "\n",
    "print(f\"Selected {len(id_train)} for train and {len(id_valid)} for validation, plus {len(id_valid_from_train)} from train to extend validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "eoIwEqL0CuQp",
    "outputId": "23b07117-655b-4168-eb51-1b7e0a458068"
   },
   "outputs": [],
   "source": [
    "selected_images = cocoTrain.loadImgs(id_train)\n",
    "\n",
    "img = selected_images[8]\n",
    "I = io.imread(img['coco_url'])\n",
    "plt.axis('off')\n",
    "plt.imshow(I)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(I); plt.axis('off')\n",
    "annIds = cocoTrain.getAnnIds(imgIds=img['id'], iscrowd=None)\n",
    "anns = cocoTrain.loadAnns(annIds)\n",
    "cocoTrain.showAnns(anns)\n",
    "print(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltwTdIMsE6qp"
   },
   "outputs": [],
   "source": [
    "#append timestamp to output dir\n",
    "output_dir = output_name + \"_\" + str(int(time.time()))\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "Path(output_dir+\"/train/labels/\").mkdir(parents=True, exist_ok=True)\n",
    "Path(output_dir+\"/train/images/\").mkdir(parents=True, exist_ok=True)\n",
    "Path(output_dir+\"/valid/labels/\").mkdir(parents=True, exist_ok=True)\n",
    "Path(output_dir+\"/valid/images/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Convert annotations\n",
    "convert_coco_to_yolo(cocoTrain, id_train, output_dir+\"/train/labels/\")\n",
    "convert_coco_to_yolo(cocoVal, id_valid, output_dir+\"/valid/labels/\")\n",
    "convert_coco_to_yolo(cocoTrain, id_valid_from_train, output_dir+\"/valid/labels/\")\n",
    "\n",
    "download_copy_images_pool(img_folder, output_dir+\"/train/images/\", cocoTrain, id_train)\n",
    "download_copy_images_pool(img_folder, output_dir+\"/valid/images/\", cocoVal, id_valid)\n",
    "download_copy_images_pool(img_folder, output_dir+\"/valid/images/\", cocoTrain, id_valid_from_train)\n",
    "\n",
    "\n",
    "# Create yaml\n",
    "yaml_to_dump = {\n",
    "    \"train\": \"./train/images\",\n",
    "    \"val\": \"./valid/images\",\n",
    "    \"nc\": len(my_categories),\n",
    "    \"names\": dict(zip(my_categories.values(), my_categories.keys()))\n",
    "}\n",
    "\n",
    "#dump to data.yaml\n",
    "with open(output_dir + \"/data.yaml\", \"w+\") as outfile:\n",
    "    yaml.dump(yaml_to_dump, outfile, default_flow_style=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71uqBqabXXqq"
   },
   "source": [
    "Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "q60rbkXMXXdC",
    "outputId": "5fc0f2c1-31f2-4033-e318-e4cc2d726c32"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(output_dir, 'zip', output_dir)\n",
    "\n",
    "from google.colab import files\n",
    "files.download(output_dir + \".zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOht2-rpZPD9"
   },
   "source": [
    "**VISUALIZA MASK to see if it is correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "w9M7b5asZTia",
    "outputId": "bf8472a7-791f-47c3-90c1-e1f7ad7286b4"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import Image, ImageDraw,ImageFont\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_path = \"./\"+ output_dir +\"/train/images/000000138385.jpg\"  # path of the image, change it\n",
    "annotation_path = \"./\"+ output_dir +\"/train/labels/000000138385.txt\"  # path of the annotation text file, change it\n",
    "\n",
    "# The Helper functions below assume that the image size is (640,640).Hence resizing the image.\n",
    "#Open the image\n",
    "img = Image.open(image_path)\n",
    "#Resize the image to 640 by 640\n",
    "img = img.resize((640, 640))\n",
    "#if you want then you can save the resized image by img.save('resized_image.jpg')\n",
    "\n",
    "# <--------- Helper functions starts here ----------------------------------->\n",
    "def maskVisualize(image,mask):\n",
    "  fontsize = 18\n",
    "  f, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
    "  ax[0].imshow(image)\n",
    "  ax[1].imshow(mask)\n",
    "\n",
    "#Define the boundary coordinates as a list of (x, y) tuples\n",
    "'''\n",
    "def draw_points_on_image(image, points):\n",
    "  #resize image to 640*640\n",
    "  resimg = cv2.resize(image, (640,640))\n",
    "  #iterate for each mask\n",
    "  for mask in points:\n",
    "    #Draw each point on the image\n",
    "    for point in mask:\n",
    "        cv2.circle(resimg, tuple(point), 1, (0,0,255), -1,)\n",
    "  #Display the image\n",
    "  cv2_imshow(resimg)\n",
    "'''\n",
    "#convert the mask from the txt file(annotation_path is path of txt file) to array of points making that mask.\n",
    "def generate_points(annotation_path=''):\n",
    "  labels=[] # this will store labels\n",
    "  #we are assuming that the image is of dimension (640,640). then you have annotated it.\n",
    "  with open(annotation_path, \"r\") as file:\n",
    "    points=[]\n",
    "    for line in file:\n",
    "      label,bbox,lis=line.split()[0],line.split()[1:5], line.split()[5:]\n",
    "      labels.append(label)\n",
    "      lis=list(map(float,lis))\n",
    "      for i in range(len(lis)):\n",
    "        lis[i]=int(lis[i]*640)\n",
    "      newlis=[]\n",
    "      i=0\n",
    "      while(i<len(lis)):\n",
    "        #appendint the coordinates as a tuple (x,y)\n",
    "        newlis.append((lis[i],lis[i+1]))\n",
    "        i+=2\n",
    "      points.append(newlis)\n",
    "    return labels,points\n",
    "\n",
    "\n",
    "#the below function convert the boundary coordinates to mask array (it shows mask if you pass 1 at show)\n",
    "#the mask array is required when we want to augument the mask also using albumentation\n",
    "def convert_boundary_to_mask_array(labels,points, show=0):\n",
    "  #Create a new image with the same size as the desired mask\n",
    "  mask = Image.new(\"L\", (640, 640), 0)\n",
    "  draw = ImageDraw.Draw(mask)\n",
    "  for i,boundary_coords in enumerate(points):\n",
    "    #boundary_coords represent boundary of one polygon\n",
    "    #Draw the boundary on the mask image\n",
    "    if len(boundary_coords) == 0:\n",
    "      continue\n",
    "    draw.polygon(boundary_coords,fill=1)\n",
    "    #Also put the label as text\n",
    "    #Compute the centroid of the polygon\n",
    "    centroid_x = sum(x for x, _ in boundary_coords) / len(boundary_coords)\n",
    "    centroid_y = sum(y for _, y in boundary_coords) / len(boundary_coords)\n",
    "    centroid = (int(centroid_x), int(centroid_y))\n",
    "    #Write the name at the centroid\n",
    "    text = str(labels[i])\n",
    "    #Write the label at the centroid\n",
    "    font = ImageFont.load_default()\n",
    "    font.size = 30\n",
    "    #text_w, text_h = draw.textsize(text, font=font)\n",
    "    text_w = draw.textlength(text, font=font)\n",
    "    text_h = font.size * 1\n",
    "    text_pos = (centroid[0] - text_w/2, centroid[1] - text_h/2)\n",
    "    draw.text(text_pos, text, font=font, fill='black')\n",
    "  #Convert the mask image to a numpy array\n",
    "  mask_array = np.array(mask)*255\n",
    "  #Show the mask image\n",
    "  if(show==1):\n",
    "    #Image.fromarray(mask_array).show()\n",
    "    cv2_imshow(mask_array)\n",
    "  return mask_array\n",
    "\n",
    "#function that takes mask path (yolov8 seg txt file) and return mask of an image (shape of mask == shape of image)\n",
    "def generate_mask(annotation_path='',show=0):\n",
    "  #pass show=1 for showing the generated mask\n",
    "  #firstly we generate the points (coordinates) from the annotations\n",
    "  labels,points=generate_points(annotation_path)\n",
    "  #once we get the points we will now generate the mask image from these points (binary mask image (black/white))\n",
    "  #mask is represented by white and ground is represented as black\n",
    "  mask_array=convert_boundary_to_mask_array(labels,points,show)\n",
    "  return mask_array\n",
    "# <---------- Helper Functions Ends here ------------------------------------------------------------->\n",
    "\n",
    "mask_array=generate_mask(annotation_path=annotation_path,show=0)\n",
    "maskVisualize(np.array(img),mask_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "OFG0wElBoC8c",
    "outputId": "75d88c28-7266-4d0a-9584-599255b5d77b"
   },
   "outputs": [],
   "source": [
    "##Show bboxes\n",
    "img = cv2.imread(image_path)\n",
    "dh, dw, _ = img.shape\n",
    "\n",
    "with open(annotation_path, \"r\") as file:\n",
    "  points=[]\n",
    "  for dt in file:\n",
    "    label,bbox=dt.split()[0],dt.split()[1:5]\n",
    "\n",
    "    # Split string to float\n",
    "    x = float(bbox[0])\n",
    "    y = float(bbox[1])\n",
    "    w = float(bbox[2])\n",
    "    h = float(bbox[3])\n",
    "\n",
    "    # Taken from https://github.com/pjreddie/darknet/blob/810d7f797bdb2f021dbe65d2524c2ff6b8ab5c8b/src/image.c#L283-L291\n",
    "    # via https://stackoverflow.com/questions/44544471/how-to-get-the-coordinates-of-the-bounding-box-in-yolo-object-detection#comment102178409_44592380\n",
    "    l = int((x - w / 2) * dw)\n",
    "    r = int((x + w / 2) * dw)\n",
    "    t = int((y - h / 2) * dh)\n",
    "    b = int((y + h / 2) * dh)\n",
    "\n",
    "    if l < 0:\n",
    "        l = 0\n",
    "    if r > dw - 1:\n",
    "        r = dw - 1\n",
    "    if t < 0:\n",
    "        t = 0\n",
    "    if b > dh - 1:\n",
    "        b = dh - 1\n",
    "\n",
    "    cv2.rectangle(img, (l, t), (r, b), (0, 0, 255), 1)\n",
    "    cv2.putText(img, label, (l, t), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36,255,12), 2)\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6q5o9Y8aO3H"
   },
   "outputs": [],
   "source": [
    "!rm -r prova*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
