# Hyperparameter Configuration for Mask R-CNN Training
# ====================================================
# This file contains all hyperparameter settings for training optimization
# Modify these values to customize the hyperparameter search space

# Training Arguments (Command Line Defaults)
# ------------------------------------------
training:
  trials: 50              # Number of hyperparameter optimization trials
  train_pct: 0.8              # Percentage of data to use for training (0.0-1.0)
  patience: 10                # Early stopping patience (epochs)
  save_top_k: 5               # Number of top trials to save checkpoints for
  #seed: 42                   # Random seed for reproducibility, uncomment if needed
  num_workers: 4              # Number of worker processes for loading data

model:
  version: 1                  # Mask R-CNN model version of Pytorch (1 or 2)

# Optuna Hyperparameter Search Space
# ----------------------------------
# Each parameter can be defined with different types:
# - float: {low: min_value, high: max_value, log: true/false}
# - int: {low: min_value, high: max_value, step: step_size}
# - categorical: {choices: [option1, option2, ...]}

hyperparameters:
  # Learning Rate
  lr:
    low: 1.0e-5               # Minimum learning rate
    high: 1.0e-2              # Maximum learning rate  
    log: true                 # Use logarithmic sampling
    
  # Batch Size
  batch_size:
    choices: [2, 4, 8]        # Available batch sizes (adjust based on GPU memory)
    
  # Optimizer Selection
  optimizer:
    choices: ["adam"]         # Available optimizers: adam, sgd, adamw
    
  # Training Epochs
  num_epochs:
    low: 10                   # Minimum number of epochs
    high: 100                 # Maximum number of epochs
    step: 10                  # Step size for epoch sampling
    
  # Regularization
  weight_decay:
    low: 1.0e-6               # Minimum weight decay
    high: 1.0e-2              # Maximum weight decay
    log: true                 # Use logarithmic sampling
    
  # Gradient Clipping
  use_grad_clip:
    choices: [true, false]    # Whether to use gradient clipping
    
  max_grad_norm:
    low: 0.1                  # Minimum gradient norm for clipping
    high: 10.0                # Maximum gradient norm for clipping
    log: true                 # Use logarithmic sampling
    
  # Learning Rate Scheduling
  use_scheduler:
    choices: [true, false]    # Whether to use learning rate scheduler
  lr_scheduler:
    step_size: 5              # Step size for scheduler
    gamma: 0.5                # Gamma value for scheduler

# Data Augmentation
# -----------------
augmentation:
  horizontal_flip: 0.0        # Probability of horizontal flip (0.0-1.0)
  gray_scale: 0.0             # Probability of converting image to grayscale (0.0-1.0)
  brightness:
    min: 0.875                # Minimum brightness factor
    max: 1.125                # Maximum brightness factor
  contrast:
    min: 0.5                  # Minimum contrast factor
    max: 1.5                  # Maximum contrast factor
  saturation:
    min: 0.5                  # Minimum saturation factor
    max: 1.5                  # Maximum saturation factor
  hue:
    min: -0.05                # Minimum hue adjustment
    max: 0.05                 # Maximum hue adjustment
